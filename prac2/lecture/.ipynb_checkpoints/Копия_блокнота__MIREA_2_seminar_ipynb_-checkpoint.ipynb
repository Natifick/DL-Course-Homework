{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ8rTFmQ0ueR"
   },
   "source": [
    "# **Разбор практики 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9P9bWaC9QQJm"
   },
   "source": [
    "## **Задача 2**. Cделать нейрон, соответствующий оператору НЕ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hh8sSJkEWNmT"
   },
   "outputs": [],
   "source": [
    "class Neuron(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc = torch.nn.Linear(1, 1, bias=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9HoH1koVQXi",
    "outputId": "e3020bb5-04c1-45cf-937a-77d6c2337325"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.9774]], requires_grad=True), Parameter containing:\n",
       " tensor([0.1165], requires_grad=True))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron = Neuron()\n",
    "neuron.fc.weight, neuron.fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLmGhtWFTYlV",
    "outputId": "9ca8cb0a-4683-44d6-e910-69e6908a587c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-1.]], requires_grad=True), Parameter containing:\n",
       " tensor([1.], requires_grad=True))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron.fc.weight.data = torch.tensor([[-1.0]])\n",
    "neuron.fc.bias.data = torch.tensor([1.0])\n",
    "neuron.fc.weight, neuron.fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFr5InkDTf-r",
    "outputId": "6504e778-9bd4-4c5f-c2f8-67d22bb522d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.0])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXJqgPEwAwHa",
    "outputId": "12c3a893-da2c-4b19-de63-0a803b132b38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRxJxcRJQsMz"
   },
   "source": [
    "## **Задача 3**. Cделать нейрон, соответствующий оператору И."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dvDtA7HX3V6"
   },
   "outputs": [],
   "source": [
    "class Neuron(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc = torch.nn.Linear(2, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olMqAnQtX5NQ",
    "outputId": "d3b3ffe4-f637-4338-a46f-9db503a316ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.4475]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.0402], requires_grad=True))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron = Neuron()\n",
    "neuron.fc.weight, neuron.fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAtwMX7HQ0aj",
    "outputId": "53bb0196-ecaf-489c-858e-c3d420d454aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[1., 1.]], requires_grad=True), Parameter containing:\n",
       " tensor([-1.5000], requires_grad=True))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron.fc.weight.data = torch.tensor([[1.0, 1.0]])\n",
    "neuron.fc.bias.data = torch.tensor([-1.5])\n",
    "neuron.fc.weight, neuron.fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P27EdNkrXloh",
    "outputId": "96718328-9f63-41df-8077-3791a2d6b905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.0, 0.0])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BJc_ipGrei3",
    "outputId": "c04b6405-d7ae-4e49-a6c1-6f478572f17a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 0.0 ])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjVTdBf-rei5",
    "outputId": "2788282c-a684-43c1-f219-3d16f45f14d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.0, 1.0 ])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyomxCJUrei5",
    "outputId": "9b335917-e009-479c-e75d-9d1565422b8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 1.0 ])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRuSrP7JQ00i"
   },
   "source": [
    "## **Задача 4**. Cделать нейрон, соответствующий оператору ИЛИ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23RuhFqbQ24-"
   },
   "outputs": [],
   "source": [
    "neuron.fc.weight.data = torch.tensor([[1., 1.]])\n",
    "neuron.fc.bias.data = torch.tensor([-0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-BZHFqnXpLL",
    "outputId": "7105825d-66f2-48db-a250-8a3bfe6be45d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.0, 0.0])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZuFtRlvyixQ",
    "outputId": "8181961c-7669-4a37-c4ce-1277622af170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 0.0 ])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyu88Kg0yixR",
    "outputId": "26449834-8084-4c6a-a696-141449d0622f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.0, 1.0 ])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2OhYEC7yixS",
    "outputId": "0100e5f4-c3a6-4188-9c5b-42cf823eb1e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 1.0 ])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b95Z8u7Q3OL"
   },
   "source": [
    "## **Задача 5**. Cделать нейрон, соответствующий оператору XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWP7ee7tjCGv"
   },
   "outputs": [],
   "source": [
    "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
    "neuron.fc.bias.data = torch.tensor([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgDrZ7PBjGwJ"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([0.0, 0.0])\n",
    "neuron(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjM7DFps2rBi"
   },
   "source": [
    "# **Занятие 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlS1ciOPBg7g"
   },
   "source": [
    "# [Pytorch autograd](https://pytorch.org/docs/stable/autograd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kP06X1SrzLlm"
   },
   "source": [
    "[Tutorial](https://www.youtube.com/watch?v=MswxJw-8PvE)\n",
    "\n",
    "[Slides](https://app.diagrams.net/#G1bq3akhmA5DGRCiFYJfNPSn7il2wvCkEY)\n",
    "\n",
    "[Torch C++ Binary operations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp)\n",
    "\n",
    "[Torch C++ Activations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/Activation.cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alR-VHX_gnQK"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipOjjh8OCk4u"
   },
   "outputs": [],
   "source": [
    "def show_tensor_params(*tensors):\n",
    "  for x in tensors:\n",
    "    print('---')\n",
    "    print(f\"data - {x.data}\")\n",
    "    print(f\"grad - {x.grad}\")\n",
    "    print(f\"grad_fn - {x.grad_fn}\")\n",
    "    print(f\"req_grad - {x.requires_grad}\")\n",
    "    print(f\"is_leaf - {x.is_leaf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXas0qEnybl9",
    "outputId": "6be6303b-e0d2-46c6-fbf0-15350146d570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - 5.0\n",
      "grad - None\n",
      "grad_fn - None\n",
      "req_grad - False\n",
      "is_leaf - True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.0)\n",
    "show_tensor_params(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuymHxbjzDfP"
   },
   "source": [
    "All Tensors that have **requires_grad** which is **False** will be leaf Tensors by convention.\n",
    "\n",
    "For Tensors that have **requires_grad** which is **True**, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so **grad_fn** is None.\n",
    "\n",
    "Only leaf Tensors will have their **grad** populated during a call to backward(). To get grad populated for non-leaf Tensors, you can use retain_grad().[[Link]](https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5NE4zRPyqTT"
   },
   "outputs": [],
   "source": [
    "#Slide A4\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0)\n",
    "c = a*b\n",
    "\n",
    "c.backward()\n",
    "# (2 * c).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-TbdvmH-oaM",
    "outputId": "b6e4688f-b026-44e1-f848-1d0b19fb86c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - 2.0\n",
      "grad - 3.0\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n",
      "---\n",
      "data - 3.0\n",
      "grad - None\n",
      "grad_fn - None\n",
      "req_grad - False\n",
      "is_leaf - True\n",
      "---\n",
      "data - 6.0\n",
      "grad - None\n",
      "grad_fn - <MulBackward0 object at 0x7f76788e9640>\n",
      "req_grad - True\n",
      "is_leaf - False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "show_tensor_params(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqUcFO2rCXni"
   },
   "outputs": [],
   "source": [
    "#Slide Simple5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYTsuKc3Fn8r"
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = a*b\n",
    "d = torch.tensor(4.0, requires_grad=True)\n",
    "e = c*d\n",
    "\n",
    "c.retain_grad()\n",
    "e.retain_grad()\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egTBJvIBF5EO",
    "outputId": "3be63421-eeec-4322-9a3f-a85ba26c410d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - 2.0\n",
      "grad - 12.0\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n",
      "---\n",
      "data - 3.0\n",
      "grad - 8.0\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n",
      "---\n",
      "data - 6.0\n",
      "grad - 4.0\n",
      "grad_fn - <MulBackward0 object at 0x7f760638e640>\n",
      "req_grad - True\n",
      "is_leaf - False\n",
      "---\n",
      "data - 4.0\n",
      "grad - 6.0\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n",
      "---\n",
      "data - 24.0\n",
      "grad - 1.0\n",
      "grad_fn - <MulBackward0 object at 0x7f76063bf1c0>\n",
      "req_grad - True\n",
      "is_leaf - False\n"
     ]
    }
   ],
   "source": [
    "show_tensor_params(a, b, c, d, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "W5Cs2_REGgOS",
    "outputId": "f19b45fb-c16a-4bfd-f417-70467d4e18ac"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3de2fcb7bcd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "#In place 1\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = a*b\n",
    "d = torch.tensor(4.0, requires_grad=True)\n",
    "e = c*d\n",
    "c += 1\n",
    "\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WeqfWzYGhKG",
    "outputId": "468d7422-701b-4d24-efd9-46752c00fe00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(c._version)\n",
    "print(d._version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLZ3Z4qIH4J4"
   },
   "outputs": [],
   "source": [
    "#In place 2\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = a*b\n",
    "d = torch.tensor(4.0, requires_grad=True)\n",
    "e = c+d\n",
    "c += 1\n",
    "\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ySSjlRUIH0e",
    "outputId": "438640d8-0b64-4158-b190-9c8b8e2f6b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(c._version)\n",
    "print(d._version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jbSqPGkILEw"
   },
   "outputs": [],
   "source": [
    "# отвязка от графа\n",
    "k = e.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLKUQ08AJhZT",
    "outputId": "f8e45e3e-ea45-491b-f7d3-5b962904a05b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.storage == e.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eqo-PW2kJkaG",
    "outputId": "7da36c23-b6c4-40c4-ea33-2e1e96a4d368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - 10.0\n",
      "grad - None\n",
      "grad_fn - <AddBackward0 object at 0x7f76778994f0>\n",
      "req_grad - True\n",
      "is_leaf - False\n",
      "---\n",
      "data - 10.0\n",
      "grad - None\n",
      "grad_fn - None\n",
      "req_grad - False\n",
      "is_leaf - True\n"
     ]
    }
   ],
   "source": [
    "show_tensor_params(e, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8urvcsAKi62"
   },
   "source": [
    "# Создание собственной библиотеки автоматического дифференцирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txwYkEHMftme"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urGQXw9GgdQt"
   },
   "source": [
    "### Простой пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPNsEPbZfwXm"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  return 3*x**2 - 4*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKMjYubGfzo5",
    "outputId": "a355370b-c699-4b37-d52f-3914d1c18b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "2Mufja5Mf2dD",
    "outputId": "f3356b74-4ff8-4ecc-d482-cf7c005e3586"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f76062d38e0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(-5, 5, 0.25)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzRAdjhFgGo8",
    "outputId": "dbe82fa6-9bde-44fc-d225-048b7930d2f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.000003001384925"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 0.000001\n",
    "x = 2\n",
    "(f(x + h) - f(x))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOszwXaTgkd4"
   },
   "source": [
    "### Более сложный пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOzPl8NWghve",
    "outputId": "b7a24bc1-0226-4efd-f4be-4d4a1f8ead0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "a = 2.0\n",
    "b = -3.0\n",
    "c = 10.0\n",
    "d = a*b + c\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9Xx4_omgrkm",
    "outputId": "fdc97882-88ee-45ab-ffd7-8da8ee787c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 4.0\n",
      "d2 4.0001\n",
      "slope 0.9999999999976694\n"
     ]
    }
   ],
   "source": [
    "h = 0.0001\n",
    "\n",
    "# inputs\n",
    "a = 2.0\n",
    "b = -3.0\n",
    "c = 10.0\n",
    "\n",
    "d1 = a*b + c\n",
    "c += h\n",
    "d2 = a*b + c\n",
    "\n",
    "print('d1', d1)\n",
    "print('d2', d2)\n",
    "print('slope', (d2 - d1)/h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wle8vv7_grKJ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlDJrMMsOgNh"
   },
   "source": [
    "https://pytorch.org/tutorials/beginner/examples_autograd/polynomial_custom_function.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPyPkdq5RH94"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5-hnsEiPIz9"
   },
   "outputs": [],
   "source": [
    "class Exp(Function):\n",
    "  \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "  @staticmethod\n",
    "  def forward(ctx, i):\n",
    "    \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "    \"\"\"\n",
    "    result = i.exp()\n",
    "    ctx.save_for_backward(result)\n",
    "    return result\n",
    "\n",
    "  @staticmethod\n",
    "  def backward(ctx, grad_output):\n",
    "    \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "    \"\"\"\n",
    "    print(ctx.saved_tensors)\n",
    "    result, = ctx.saved_tensors\n",
    "    return grad_output * result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elaOA8bdRiMc",
    "outputId": "dbdec323-534b-40e2-b2d0-ad4b6e1dd956"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.3891, grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use it by calling the apply method\n",
    "input = torch.tensor(2.0, requires_grad=True)\n",
    "output = Exp.apply(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlcZLt-RSGgG",
    "outputId": "4af4b18f-d2ed-450a-d86d-7ac6f5f8dfa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.38905609893065"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.exp(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Om6dn414SQeA",
    "outputId": "9b16cba0-46cb-4b74-e0b0-35117af043e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(7.3891, grad_fn=<ExpBackward>),)\n",
      "---\n",
      "data - 7.389056205749512\n",
      "grad - None\n",
      "grad_fn - <torch.autograd.function.ExpBackward object at 0x7f76064c6b80>\n",
      "req_grad - True\n",
      "is_leaf - False\n",
      "---\n",
      "data - 2.0\n",
      "grad - 7.389056205749512\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "output.backward()\n",
    "show_tensor_params(output)\n",
    "show_tensor_params(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_14IqfeSnLM"
   },
   "source": [
    "**Задание**: реализуйте backward для Polynomial 0.5 * (5 * input ** 3 - 3 * input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5cNegVYOd8u"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Polynomial(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        return (7.5 * input ** 2 - 1.5) * grad_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fA2PNhudUNij"
   },
   "source": [
    "Практическое задание: написать собственный движок автоматического дифференцирования, а именно: реализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chDdD9oSUlUJ"
   },
   "outputs": [],
   "source": [
    "class Value:\n",
    "    \"\"\" stores a single scalar value and its gradient \"\"\"\n",
    "\n",
    "    def __init__(self, data, _children=(), _op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0\n",
    "        # internal variables used for autograd graph construction\n",
    "        self._backward = lambda: None # function \n",
    "        self._prev = set(_children) # set of Value objects\n",
    "        self._op = _op # the op that produced this node, string ('+', '-', ....)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(other.data + self.data, (self, other), '+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(other.data * self.data, (self, other), '*')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad * other.data\n",
    "            other.grad += out.grad * self.data\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "        out = Value(self.data ** other, (self,), '**')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad * other * (self.data ** (other - 1))\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def relu(self):\n",
    "        out = Value(self.data if self.data > 0 else 0, (self,), 'relu')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad if self.data > 0 else 0\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        # topological order all of the children in the graph\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        # go one variable at a time and apply the chain rule to get its gradient\n",
    "        self.grad = 1\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "\n",
    "    def __neg__(self): # -self\n",
    "        return self * -1\n",
    "\n",
    "    def __radd__(self, other): # other + self\n",
    "        return self + other\n",
    "\n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)\n",
    "\n",
    "    def __rsub__(self, other): # other - self\n",
    "        return other + (-self)\n",
    "\n",
    "    def __rmul__(self, other): # other * self\n",
    "        return self * other\n",
    "\n",
    "    def __truediv__(self, other): # self / other\n",
    "        return self * other**-1\n",
    "\n",
    "    def __rtruediv__(self, other): # other / self\n",
    "        return other * self**-1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data}, grad={self.grad})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vY7OzWjuUiaa"
   },
   "outputs": [],
   "source": [
    "def test_sanity_check():\n",
    "\n",
    "    x = Value(-4.0)\n",
    "    z = 2 * x + 2 + x\n",
    "  \n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    xmg, ymg = x, y\n",
    "\n",
    "    x = torch.Tensor([-4.0]).double()\n",
    "    x.requires_grad = True\n",
    "    z = 2 * x + 2 + x\n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    xpt, ypt = x, y\n",
    "\n",
    "    \n",
    "    # forward pass went well\n",
    "    assert ymg.data == ypt.data.item()\n",
    "    # backward pass went well\n",
    "    print(xmg, xpt, xpt.grad)\n",
    "    assert xmg.grad == xpt.grad.item()\n",
    "\n",
    "\n",
    "def test_more_ops():\n",
    "\n",
    "    a = Value(-4.0)\n",
    "    b = Value(2.0)\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c += c + 1\n",
    "    c += 1 + c + (-a)\n",
    "    d += d * 2 + (b + a).relu()\n",
    "    d += 3 * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g += 10.0 / f\n",
    "    g.backward()\n",
    "    amg, bmg, gmg = a, b, g\n",
    "\n",
    "    a = torch.Tensor([-4.0]).double()\n",
    "    b = torch.Tensor([2.0]).double()\n",
    "    a.requires_grad = True\n",
    "    b.requires_grad = True\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c = c + c + 1\n",
    "    c = c + 1 + c + (-a)\n",
    "    d = d + d * 2 + (b + a).relu()\n",
    "    d = d + 3 * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g = g + 10.0 / f\n",
    "    g.backward()\n",
    "    apt, bpt, gpt = a, b, g\n",
    "\n",
    "    tol = 1e-6\n",
    "    # forward pass went well\n",
    "    assert abs(gmg.data - gpt.data.item()) < tol\n",
    "    # backward pass went well\n",
    "    assert abs(amg.grad - apt.grad.item()) < tol\n",
    "    assert abs(bmg.grad - bpt.grad.item()) < tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LgTiYeZ-WGk"
   },
   "outputs": [],
   "source": [
    "a = Value(-4.0)\n",
    "b = Value(2.0)\n",
    "d = Value(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0svSAs2h0Ap"
   },
   "outputs": [],
   "source": [
    "c = a + b\n",
    "e = c * d\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9n8DN6RYkrx",
    "outputId": "443147d0-b200-436d-90d0-4f9db9a30fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=-4.0, grad=46.0) tensor([-4.], dtype=torch.float64, requires_grad=True) tensor([46.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1T198QDQYh_q"
   },
   "outputs": [],
   "source": [
    "test_more_ops()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-KbDOhMYHZ1"
   },
   "source": [
    "# Обучение на основе собственной бибилотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVK1JLXom0Ze"
   },
   "source": [
    "## Многослойный перцептрон на основе класса Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkl70dxhkcQN"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Module:\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Neuron(Module):\n",
    "    #                  nin hao ma\n",
    "    def __init__(self, nin, nonlin=True):\n",
    "        self.w = [Value(1) for i in range(nin)]\n",
    "        self.b = Value(0)\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mid = sum([self.w[i] * x[i] for i in range(len(x))]) + self.b\n",
    "        act = mid.relu() if self.nonlin else mid\n",
    "        return act\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"\n",
    "\n",
    "class Layer(Module):\n",
    "\n",
    "    def __init__(self, nin, nout, **kwargs):\n",
    "        self.neurons = [Neuron(nin, kwargs['nonlin']) for i in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = [n(x) for n in self.neurons]\n",
    "        return out[0] if len(out) == 1 else out\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for n in self.neurons:\n",
    "            params += n.parameters()\n",
    "        return params\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n",
    "\n",
    "class MLP(Module):\n",
    "\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i+1], nonlin=(i!=len(nouts)-1)) for i in range(len(nouts))]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for l in self.layers:\n",
    "            params += l.parameters()\n",
    "        return params\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr = '\\n'.join(str(layer) for layer in self.layers)\n",
    "        return f\"MLP of [{repr}]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkkaE1V1m5i5"
   },
   "source": [
    "## Обучение многослойного перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWy-H8eCn2zm"
   },
   "source": [
    "Сам перцептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3La6nRi4m920",
    "outputId": "aa871fdc-ce8b-4775-8214-914e96d5da95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)]\n",
      "Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)]\n",
      "Layer of [LinearNeuron(4)]]\n",
      "number of parameters 41\n"
     ]
    }
   ],
   "source": [
    "model = MLP(3, [4, 4, 1])\n",
    "print(model)\n",
    "print(\"number of parameters\", len(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvkZVOLcnvqu"
   },
   "source": [
    "Набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLJULsNanpVC"
   },
   "outputs": [],
   "source": [
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuCTaTB8n5l0",
    "outputId": "596960ad-8414-4946-f0a8-e14c09e55160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 1889.0, accuracy 0.0%\n",
      "step 400 loss 0.8491560611586679, accuracy 0.0%\n",
      "step 800 loss 0.5598632663471556, accuracy 25.0%\n",
      "step 1200 loss 0.13218400504446332, accuracy 75.0%\n",
      "step 1600 loss 0.05611870318542738, accuracy 100.0%\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "for k in range(2_000):\n",
    "\n",
    "    # forward\n",
    "    out = [model(x) for x in xs]\n",
    "\n",
    "    # calculate loss (mean square error)\n",
    "    acc = 0\n",
    "    total_loss = 0\n",
    "    for y_pred, y_true in zip(out, ys):\n",
    "      total_loss += (y_pred - y_true) ** 2\n",
    "      acc += round(y_pred.data) == y_true\n",
    "    total_loss = total_loss / len(ys)\n",
    "    acc = acc / len(ys)\n",
    "    history.append(total_loss.data)\n",
    "    \n",
    "    # backward (zero_grad + backward)\n",
    "    model.zero_grad()\n",
    "    total_loss.backward()\n",
    "    \n",
    "    # update\n",
    "    learning_rate = 0.001\n",
    "    for p in model.parameters():\n",
    "        p.data = p.data - learning_rate * p.grad\n",
    "    \n",
    "    \n",
    "    if k % 400 == 0:\n",
    "        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "bdUspbivGbDS",
    "outputId": "d3ff9ab1-5c3b-422f-fa78-556d8bf35116"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"log(loss)\")\n",
    "plt.plot(range(len(history)), [np.log(h) for h in history])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4maaWL5yg-f"
   },
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yyK39RYo084"
   },
   "source": [
    "**Домашнее задание 1.** Доделать практику. Оформить код в три отдельных модуля `autograd`, `nn`, `train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdzPyQ-hylKH"
   },
   "source": [
    "**Домашнее задание 2 (Опционально).** Создать свою функцию softmax, наследуемую от `torch.autograd.Function` и имплементировать forward и backward проход. Сравнить со стандартной функцией в Pytorch. \n",
    "[Создание функций](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html) [Софтмакс](https://congyuzhou.medium.com/softmax-3408fb42d55a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGMpj9Pf61n2"
   },
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VPpRO6H6SHF"
   },
   "source": [
    "**Домашнее задание 3 (Опционально).** Добавить функцию софтмакс в собственну библиотеку автоматического дифференцирования. Сравнить с пунктом 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YJfxtqSphFs"
   },
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRRgw0HNsr_a"
   },
   "source": [
    "**Домашнее задание 4 (Опционально).** Добавить визуализацию обучения. Потом мы пройдем более подробно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5AWW52REfn5"
   },
   "source": [
    "https://docs.wandb.ai/guides/integrations/pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekFfy3cWVOIW"
   },
   "source": [
    "https://docs.wandb.ai/ref/python/watch  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9G4SOp28ok0o"
   },
   "source": [
    "https://docs.wandb.ai/guides/track/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lumiR8oykL04"
   },
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xw3c6P7BkP9b"
   },
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udPv0ufwkxOv"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init(project=\"polynom_learning_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xtpc9MAUodNs"
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MRuSrP7JQ00i",
    "1b95Z8u7Q3OL"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
